---
layout: post
title: 大规模社会化数据--概念与实现（0）
excerpt: 在这个系列文章中，我将一步步的分享我在大规模社会化数据的实践中获得的经验。这篇文章将简要介绍我在做什么，以及这个东西有什么用。
modified: 2016-03-09
tags: [知识图谱, 大数据, 风控, Hadoop, HBase, Elastic Search, Titan Graph]
comments: true
categories: tech
---

这里将会是一个系列文章，讲述了我目前在做的一个很重要的工作，用各种技术来实现海量异构知识的获取、整合、分析、查询等一系列的工作，非常的有用、有意思、有挑战。鉴于时间有限，我会尽量抽时间把这个系列写下去。

本文将简要介绍人们对于数据管理的演化，大规模社会化的数据给已有技术带来的挑战，以及我们如何能很好的解决这些挑战同时又为未来做好准备。

## 回望历史
人们一直在寻找管理知识和使用知识的更高效的方式，但受限于当时的技术条件，人们有时无法解决已有的问题，当然也没有能力和胆量来想象更复杂的世界。当人们还只知道结绳记事的适合，他们无法想象能用文字把事情的细节描述的如此清晰。当印刷术还不完善的时候，文字还只是极少部分人的特权，大部分人活在愚昧之中。阿兰图灵设计的密码破译机[Bombe](https://en.wikipedia.org/wiki/Bombe)以机器的运算代替密码学家们的手动分析，战胜了强大的[Enigma密码机](https://en.wikipedia.org/wiki/Enigma_machine)，使得纳粹的加密电文显露无疑，为二战中盟军的最后胜利提供了强有力的支持。这些看似和数据管理无关的历史，其实都是人们对信息的加工，如何能更准确、更高效、更安全、更方便的共享知识，产生新的知识和财富。

现代的计算机工业出现后，出现了很多的高效的数据管理技术，不得不提的是各种类型的数据库管理系统。[面向对象的数据库(OODBMS)](https://en.wikipedia.org/wiki/Object_database)仿照面向对象的编程技术，使得其可以直接被C++, C#, Java等面向对象编程语言直接使用，但因为其复杂性变得难以优化。[关系型数据库(RDMBS)](https://en.wikipedia.org/wiki/Relational_database_management_system)因其简洁的结构和强有力的数学基础，很快赢得了商业上的成功。SQL语句给RDBMS提供了接近自然语言的接口，使在线的随机OLTP任务和离线的OLAP分析任务可以统一在一个框架下。现代的RDBMS系统提供了更多的高级功能，比如安全性、事务操作、高可用等，成为了计算机软件开发者和数据分析科学家的必备技能。

互联网时代的来临，给人们带来更便捷的生活的同时，也给数据的加工和处理技术带来了更大的挑战，大数据技术也从学术界的畅想变为工业界的现实。人们在网络上的一举一动，在大数据的技术下，已经不是什么隐私，而变成了网络服务提供者的资产。你在购物网站上随意点击的几个商品，会被电商网站抽取出关键路径，然后给你推荐商品。骗子在网上发布的欺诈帖子，会作为他一生的污点记录在各种搜索引擎、骗子数据库或者网贷平台中。主要技术包括[GFS](https://en.wikipedia.org/wiki/Google_File_System)和[HDFS](http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html)一类的分布式文件系统，[BigTable](https://en.wikipedia.org/wiki/BigTable)、[HBase](http://hbase.apache.org)和[Cassandra](http://cassandra.apache.org)一类的NoSql存储，[MapReduce](https://en.wikipedia.org/wiki/MapReduce)、[Spark](http://spark.apache.org)和[Tez](https://tez.apache.org/)一类的计算模型，和[Mahout](http://mahout.apache.org)和[MLlib](http://spark.apache.org/mllib/)一类的机器学习算法库，等等。无数的顶尖工程师和科学家的努力，让童话变成现实，改变着我们的每一天的生活。

## 现在的挑战

我们在以前所未有的速度创造和记录着各种各样的数据，而我们对于数据分析和挖掘的胃口也史无前例的飞速增长着。大数据是个热词，各种人都在谈论着，计算机从业人纷纷变成了大数据专家，猎头们撒开大网，打爆每个标着“大数据”的简历。大数据是个好东西，但它不是万能药，需要对症下药。

大数据技术的能力，可以总结为4个V，Volume，Velocity，Variety和Value。现有的大数据技术，以Volume（大的数据量）为开始，逐步加入了velocity（时效性）考量。Value（价值）则体现在两个方面，一是原始数据的价值，1TB的信用卡账单和1TB的网站点击日志，其价值自然相差很多；二是，需要从这些数据中得到价值，不能仅仅为了好看的技术而白费力气。

现在的数据类别越来越多、格式越来越庞杂，但大数据技术对于Variety（多样性）的支持似乎并没有开始。举一个例子，一个借贷中介为了找到潜在的客户，会将自己的联系方式等信息通过发帖等方式放到网络上。在替客户借款的过程中，因为成本或者操作等原因，该中介有可能将网络上的信息用在实际的借款申请中。如果这个金融机构能够有深度的整合并及时的查阅这些帖子信息，就能分辨出这个中介，从而大幅度的提升自己的风控水平。

但实际的情况是，要做到高效准确的整合异构数据源并且做到灵活的查询，是非常困难的。最常用的数据管理技术是关系型数据库，对于实现确定好格式和类型的数据表高效且表达能力强，但对于灵活可变的数据却很无可奈何。面向对象的数据库能在一定程度上处理嵌套的灵活数据，但性能差且规模有限。MapReduce和Spark足够灵活，能实现各种的逻辑，同时使用起来复杂且无法为在线服务提供支持。传统的语义网技术能将语义嵌入到数据中从而具有自表达能力，但难于被一般人理解和使用，scale-out的能力也不好。

## 站在巨人的肩膀上
即便面临着前述的诸多困难，我们并不是没有趁手的工具。
在理论层面，我们[语义网](https://en.wikipedia.org/wiki/Semantic_web)，[OWL]()和[RDF]()等，基础类库我们有[Apache Jena](http://jena.apache.org/)，单机查询引擎我们有[Sparql]()，大规模在线数据服务我们有Hbase，分布式全文检索我们有ElasticSearch，实时数据传输我们有Flume，近实时分析我们有Spark-streaming，离线跑批分析我们有MapReduce和Hive，离线迭代计算我们有Spark和MLlib。

我们现在需要的，是能充分的理解每一种工具的原理和优缺点，将它们的长处利用起来，打造出一个适用于现代大规模社会化数据的新大数据生态环境。

## 乘风远航

一个完美的大数据系统，应该是能轻松应对多种数据格式和尺寸，功能强大，表达手段丰富，易于学习和使用，执行高效，节省资源，同时适用于在线服务和离线分析。这不是一个简单的目标，不敢说我的KG系统完美的做到了，但它跨越了无数个难点，正大踏步的前进。

接下来的几篇文章我会逐步讲解我是如何将这个复杂系统拆分开研究，并一点一滴的拼接成一个完整的生态系统，包括数据的流入流出、格式转换、在线服务、离线分析、性能和存储的优化、分层特化，等等。
性急的看官，可以留意我的Github账号，不久之后就会开源出部分核心代码。
