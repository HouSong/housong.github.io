## ES数据

ES有snapshot功能，将index中的数据存到静态文件中，或者从静态文件中还原。老机房和新机房各有一个分布式的mfs，在老机房中把snapshot写到mfs里，用rsync拷贝到新机房中，然后再还原到新机房的ES里，就可以实现数据迁移。

### 制作snapshot
打开旧机房ES的页面[http://es2.bdp.cc/_plugin/kopf/](http://es2.bdp.cc/_plugin/kopf/)，进入repository页面，点击“Create snapshot”，输入*snapshot*的名字，repository选择*mfs*，indices中选择需要备份的index名。

**注意**：因为旧机房中ES机器上的用户名ID不一致，导致挂载上去的mfs在不同机器上看到的权限不同。在正式创建snapshot之前，需要手动修改权限。具体如下：假设index名称是A，有5个shards。进入`/mfs/es_snapshots/indices/`，创建目录A，在目录A中创建子目录0到4，然后把A目录和下面的子目录的权限都改为`777`。这个时候再创建这个index的snapshot。

### 数据拷贝
在新机房的ES的机器（c1-es1）上，切换到用户es，执行如下命令：
`rsync --update -avP -e 'ssh -p 2222' search@10.180.60.101:/mfs/es_snapshots/ /mfs/es_snapshots/`
无需输入密码，ssh已经打通。
对于很大的index，可以用nohup放到后台跑。

### 数据还原

进入新机房ES的监控页面[http://es.bdp.cc/_plugin/kopf/](http://es.bdp.cc/_plugin/kopf/)，在`more`中进入`snapshot`，在`repository`中选择`mfs`，下面展开的snapshot中应该有刚拷贝过来的备份。点击restore，在rename中对index重新命名，具体方法参见[文档](https://www.elastic.co/guide/en/elasticsearch/guide/current/_restoring_from_a_snapshot.html)。*新机房中yisou可以用的index都以`yisou_`开头。*

restore后，如果以前的index有tag，比如`ssd`，那么需要将这个tag去掉（新机房的机器没有tag，全部都是ssd磁盘）。可以用rest命令：

```
curl -XPUT http://es.bdp.cc/yisou_search_201511/_settings -d ' {
  "index.routing.allocation.include.tag": ""
}'
```

等一个snapshot还原后，再进行下一个。

## Hbase数据
### 准备工作
将旧机房的所有机器都加入到新机房的hbase auth的cluster中：
10.180.60.11,10.180.60.12,10.180.60.13,10.180.60.14,10.180.60.15,10.180.60.16,10.180.60.17,10.180.60.18,10.180.60.19,10.180.60.20,10.180.60.21,10.180.60.22,10.180.60.23,10.180.60.24,10.180.60.25,10.180.60.26,10.180.60.27

将新机房的ip写入旧机房的hosts文件中：

```
10.130.1.11 c1-hd-nn1.bdp.idc 
10.130.1.12 c1-hd-nn2.bdp.idc 
10.130.1.13 c1-hd-nn3.bdp.idc 
10.130.1.20 c1-hd-dn1.bdp.idc 
10.130.1.21 c1-hd-dn2.bdp.idc 
10.130.1.22 c1-hd-dn3.bdp.idc 
10.130.1.23 c1-hd-dn4.bdp.idc 
10.130.1.24 c1-hd-dn5.bdp.idc 
10.130.1.25 c1-hd-dn6.bdp.idc 
10.130.1.26 c1-hd-dn7.bdp.idc 
10.130.1.27 c1-hd-dn8.bdp.idc 
10.130.1.28 c1-hd-dn9.bdp.idc 
10.130.1.29 c1-hd-dn10.bdp.idc 
10.130.1.30 c1-hd-dn11.bdp.idc 
10.130.1.31 c1-hd-dn12.bdp.idc 
```

在新机房的Hbase中创建目标table，要求有相同的column family。

### 命令
在老机房执行命令：

```
hbase org.apache.hadoop.hbase.mapreduce.CopyTable \
  --new.name=yisou:btype \
  --peer.adr=c1-hd-nn1.bdp.idc,c1-hd-nn2.bdp.idc,c1-hd-nn3.bdp.idc:2181:/hbase \
  btype
```
参见[文档](http://blog.cloudera.com/blog/2012/06/online-hbase-backups-with-copytable-2/) ，
随后检查一下行数对不对。
还可以根据时间等进行部分的增量拷贝。
